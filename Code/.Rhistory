ls()
library(rjson)
files = list.files('/Users/Chansoo/Desktop/edsp_data/scotus/')
length(files)
files = files[1:100]
files
files[1]
files_slug = '/Users/Chansoo/Desktop/edsp_data/scotus/'
files = list.files(files_slug)
files = files[1:100]
paste(files_slug,files[1],sep='')
result = fromJSON(file=paste(files_slug,files[1],sep=''))
print(result)
result$html
nchar(result$html)
library(tm)
doc.vec = VectorSource(shakespeare)
doc.vec = VectorSource(result$html)
doc.vec
doc.corpus = Corpus(doc.vec)
doc.corpus
doc.corpus = tm_map(doc.corpus, content_transformer(tolower))
doc.corpus = tm_map(doc.corpus, removeNumbers)
doc.corpus = tm_map(doc.corpus, removePunctuation)
doc.corpus = tm_map(doc.corpus, removeWords, stopwords('english'))
doc.corpus = tm_map(doc.corpus, stripWhitespace)
doc.corpus
doc.corpus$`1`
names(doc.corpus)
inspect(doc.corpus[1])
cleanFun <- function(htmlString) {
return(gsub("<.*?>", "", htmlString))
}
removeHTML <- function(htmlString) {
return(gsub("<.*?>", "", htmlString))
}
result = fromJSON(file=paste(files_slug,files[1],sep=''))
removeHTML <- function(htmlString) {
return(gsub("<.*?>", "", htmlString))
}
doc.vec = VectorSource(result$html)
doc.corpus = Corpus(doc.vec)
doc.corpus = tm_map(doc.corpus, content_transformer(tolower))
doc.corpus = tm_map(doc.corpus, removeHTML)
doc.corpus = tm_map(doc.corpus, removeNumbers)
doc.corpus = tm_map(doc.corpus, removePunctuation)
doc.corpus = tm_map(doc.corpus, removeWords, stopwords('english'))
doc.corpus = tm_map(doc.corpus, stripWhitespace)
inspect(doc.corpus[1])
result = fromJSON(file=paste(files_slug,files[1],sep=''))
result$html
htmlBreaks <- function(htmlString) {
return(gsub("<br>", " ", htmlString))
}
htmlRemove <- function(htmlString) {
return(gsub("<.*?>", "", htmlString))
}
result = fromJSON(file=paste(files_slug,files[1],sep=''))
result$html
htmlBreaks <- function(htmlString) {
return(gsub("<br>", " ", htmlString))
}
htmlRemove <- function(htmlString) {
return(gsub("<.*?>", "", htmlString))
}
doc.vec = VectorSource(result$html)
doc.corpus = Corpus(doc.vec)
doc.corpus = tm_map(doc.corpus, content_transformer(tolower))
doc.corpus = tm_map(doc.corpus, htmlBreaks)
doc.corpus = tm_map(doc.corpus, htmlRemove)
doc.corpus = tm_map(doc.corpus, removeNumbers)
doc.corpus = tm_map(doc.corpus, removePunctuation)
doc.corpus = tm_map(doc.corpus, removeWords, stopwords('english'))
doc.corpus = tm_map(doc.corpus, stripWhitespace)
inspect(doc.corpus[1])
result = fromJSON(file=paste(files_slug,files[1],sep=''))
result$html
result$plain_text
result
result = fromJSON(file=paste(files_slug,files[10],sep=''))
result$plain_text
result
result$html_lawbox
result = fromJSON(file=paste(files_slug,files[1],sep=''))
result$html_lawbox
htmlBreaks <- function(htmlString) {
return(gsub("<br>", " ", htmlString))
}
htmlRemove <- function(htmlString) {
return(gsub("<.*?>", "", htmlString))
}
doc.vec = VectorSource(result$html)
doc.corpus = Corpus(doc.vec)
doc.corpus = tm_map(doc.corpus, content_transformer(tolower))
doc.corpus = tm_map(doc.corpus, htmlBreaks)
doc.corpus = tm_map(doc.corpus, htmlRemove)
doc.corpus = tm_map(doc.corpus, removeNumbers)
doc.corpus = tm_map(doc.corpus, removePunctuation)
doc.corpus = tm_map(doc.corpus, removeWords, stopwords('english'))
doc.corpus = tm_map(doc.corpus, stripWhitespace)
inspect(doc.corpus[1])
library(SnowballC)
doc.corpus = tm_map(doc.corpus, stemDocument)
rm(list=ls())
files_slug = '/Users/Chansoo/Desktop/edsp_data/scotus/'
files = list.files(files_slug)
files = files[1:100]
result = fromJSON(file=paste(files_slug,files[1],sep=''))
result$html_lawbox
htmlBreaks <- function(htmlString) {
return(gsub("<br>", " ", htmlString))
}
htmlRemove <- function(htmlString) {
return(gsub("<.*?>", "", htmlString))
}
doc.vec = VectorSource(result$html)
doc.corpus = Corpus(doc.vec)
doc.corpus = tm_map(doc.corpus, content_transformer(tolower))
doc.corpus = tm_map(doc.corpus, htmlBreaks)
doc.corpus = tm_map(doc.corpus, htmlRemove)
doc.corpus = tm_map(doc.corpus, removeNumbers)
doc.corpus = tm_map(doc.corpus, removePunctuation)
doc.corpus = tm_map(doc.corpus, removeWords, stopwords('english'))
doc.corpus = tm_map(doc.corpus, stemDocument)
doc.corpus = tm_map(doc.corpus, stripWhitespace)
inspect(doc.corpus[1])
review_dtm <- DocumentTermMatrix(doc.corpus)
review_dtm
inspect(review_dtm[11:20,11:20])
inspect(review_dtm[1,11:20])
result$html_lawbox
# Load Data
#########################
opinions = rep(NA,100)
for(i in 1:100){
result = fromJSON(file=paste(files_slug,files[i],sep=''))
opinions[i] = result$html_lawbox
}
opinions
nchar(opinions)
nchar(opinions[29])
nchar(opinions[28])
i=28
result = fromJSON(file=paste(files_slug,files[i],sep=''))
result
for(i in 1:100){
result = fromJSON(file=paste(files_slug,files[i],sep=''))
opinions[i] = result$html_with_citations
}
nchar(opinions)
doc.vec = VectorSource(result$html)
doc.vec = VectorSource(result$html_with_citations)
doc.corpus = Corpus(doc.vec)
doc.corpus = tm_map(doc.corpus, content_transformer(tolower))
doc.corpus = tm_map(doc.corpus, htmlBreaks)
doc.corpus = tm_map(doc.corpus, htmlRemove)
doc.corpus = tm_map(doc.corpus, removeNumbers)
doc.corpus = tm_map(doc.corpus, removePunctuation)
doc.corpus = tm_map(doc.corpus, removeWords, stopwords('english'))
doc.corpus = tm_map(doc.corpus, stemDocument)
doc.corpus = tm_map(doc.corpus, stripWhitespace)
inspect(doc.corpus[1])
result
inspect(doc.corpus[1])
doc.vec = VectorSource(opinions)
doc.corpus = Corpus(doc.vec)
doc.corpus = tm_map(doc.corpus, content_transformer(tolower))
doc.corpus = tm_map(doc.corpus, htmlBreaks)
doc.corpus = tm_map(doc.corpus, htmlRemove)
doc.corpus = tm_map(doc.corpus, removeNumbers)
doc.corpus = tm_map(doc.corpus, removePunctuation)
doc.corpus = tm_map(doc.corpus, removeWords, stopwords('english'))
doc.corpus = tm_map(doc.corpus, stemDocument)
doc.corpus = tm_map(doc.corpus, stripWhitespace)
inspect(doc.corpus[1])
review_dtm <- DocumentTermMatrix(doc.corpus)
inspect(review_dtm[1,11:20])
inspect(review_dtm[1:10,11:20])
review_dtm = removeSparseTerms(review_dtm, 0.99)
review_dtm
inspect(review_dtm[1,11:20])
inspect(review_dtm[1:10,11:20])
doc.vec = VectorSource(opinions)
doc.corpus = Corpus(doc.vec)
doc.corpus = tm_map(doc.corpus, content_transformer(tolower))
doc.corpus = tm_map(doc.corpus, htmlBreaks)
doc.corpus = tm_map(doc.corpus, htmlRemove)
doc.corpus = tm_map(doc.corpus, removeNumbers)
doc.corpus = tm_map(doc.corpus, removePunctuation)
doc.corpus = tm_map(doc.corpus, removeWords, stopwords('english'))
doc.corpus = tm_map(doc.corpus, stemDocument)
doc.corpus = tm_map(doc.corpus, stripWhitespace)
inspect(doc.corpus[1])
review_dtm <- DocumentTermMatrix(doc.corpus)
review_dtm
review_dtm = removeSparseTerms(review_dtm, 0.99)
review_dtm
findFreqTerms(review_dtm, 1000)
findFreqTerms(review_dtm, 500)
?findFreqTerms
findFreqTerms(review_dtm, 100)
findFreqTerms(review_dtm, 500)
# TF-IDF
#########################
review_dtm_tfidf <- DocumentTermMatrix(review_corpus, control = list(weighting = weightTfIdf))
# TF-IDF
#########################
review_dtm_tfidf <- DocumentTermMatrix(doc.corpus, control = list(weighting = weightTfIdf))
review_dtm_tfidf = removeSparseTerms(review_dtm_tfidf, 0.95)
review_dtm_tfidf
inspect(review_dtm_tfidf[1:10,11:20])
# Load Data
#########################
rm(list=ls())
